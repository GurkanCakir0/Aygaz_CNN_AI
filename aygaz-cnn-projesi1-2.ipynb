{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"  # AYGAZ GÖRÜNTÜ İŞLEME BOOTCAMP                                                       \n\n# PROJENİN AMACI ;\n\n    Bu projenin temel amacı, Convolutional Neural Network (CNN) tabanlı bir derin öğrenme modeli geliştirerek geniş bir veri kümesi üzerinde yer alan çeşitli hayvan türlerini sınıflandırmaktır. Proje kapsamında, CNN algoritmalarının etkili bir şekilde eğitilmesi ve test edilmesi hedeflenmektedir. Bu süreçte, seçilen veri kümesindeki hayvan görselleri kullanılarak modelin doğruluğu ve performansı analiz edilecektir. Geliştirilecek model, görüntü işleme ve sınıflandırma alanındaki teknikleri uygulamalı olarak deneyimlemek ve bu alandaki bilgi birikimini artırmak amacıyla tasarlanmıştır.","metadata":{}},{"cell_type":"markdown","source":"# KULLANILAN KÜTÜPHANELER ve FONKSİYONLARI ;\n\n* **os: Dosya ve klasör işlemleri için kullanıldı.**\n* **cv2: Görsellerle ilgili işleme yüklenmiştir.**\n* **shutil: Dosya kopyalama işlemlerinde kullanıldı**\n* **torch, sklearn: Model eğitimi ve değerlendirme aşamalarında kullanılmak üzere çağrılmıştır.**\n* **matplotlib: Veri görselleştirme için kullanılıyor.**\n* **numpy: Sayısal hesaplamalar ve veri manipülasyonu için.**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn.functional as F\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:18:39.088152Z","iopub.execute_input":"2024-12-22T19:18:39.088483Z","iopub.status.idle":"2024-12-22T19:18:39.092835Z","shell.execute_reply.started":"2024-12-22T19:18:39.088460Z","shell.execute_reply":"2024-12-22T19:18:39.091902Z"}},"outputs":[],"execution_count":387},{"cell_type":"markdown","source":"# Veri Yolunun Tanımlanması ;\n\n* **path : Kullandığımız Dataset'in konumunu belirtir**\n* **subfolder_path : Görsellerin bulunduğu alt klasörü belirler.**\n* **output_folder : Değiştirilmiş fotoğrafların kopyalanacağı çıkış klasörüdür.**\n* **selected_animals : Dataset'in içindeki seçili olan alt klasörleri belirtir.**","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/animals-with-attributes-2\"\nsubfolder_path = os.path.join(path, \"Animals_with_Attributes2/JPEGImages\")\noutput_folder = \"/kaggle/working/selected_animals\"\nos.makedirs(output_folder, exist_ok=True)\n\nselected_animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \n                    \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \n                    \"giant+panda\", \"polar+bear\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:18:39.104738Z","iopub.execute_input":"2024-12-22T19:18:39.104971Z","iopub.status.idle":"2024-12-22T19:18:39.108807Z","shell.execute_reply.started":"2024-12-22T19:18:39.104943Z","shell.execute_reply":"2024-12-22T19:18:39.108016Z"}},"outputs":[],"execution_count":388},{"cell_type":"markdown","source":"# Görsellerin kopyalanma ve Sınıflandırma süreci ;\n\n* **animal : Seçili olan hayvan sınıflarını bu değişkenin içine atanır ve işlemleri bu değişken üzerinden yapılır.**\n* **animal_folder : Gerekli işlemlerden geçen sınıfların klasör yolunu oluşturmak.**\n* **destination : Seçilen hayvan sınıfına ait bir klasör oluşturur.**\n* **image_files : Dataset'in içindeki seçili olan sınıfların ilk 650 verisini listeler.**\n* **source_file : Listelenen klasörleri kaynak klasörden hedef klasöre kopyalamak.**\n\n**Bu alanda yazdığımız kod, Datasetimizde ki veri kümesindeki belirli hayvan sınıflarına ait görselleri, eğitim ve test veri seti oluşturma amacıyla organize etmektedir. İşlem sırasında, her bir sınıf için maksimum 650 adet görsel kopyalanır ve ayrı bir klasöre yerleştirilir. Kod, temel olarak şu işlevleri yerine getirir.**","metadata":{}},{"cell_type":"code","source":"for animal in selected_animals:\n    animal_folder = os.path.join(subfolder_path, animal.replace(\" \", \"_\"))\n    if os.path.exists(animal_folder):\n        destination = os.path.join(output_folder, animal.replace(\" \", \"_\"))\n        os.makedirs(destination, exist_ok=True)\n        \n        image_files = os.listdir(animal_folder)[:650]\n        for file_name in image_files:\n            source_file = os.path.join(animal_folder, file_name)\n            if os.path.isfile(source_file):\n                shutil.copy(source_file, destination)\n        print(f\"{animal} sınıfından 650 görsel kopyalandı.\")\n    else:\n        print(f\"Klasör bulunamadı: {animal_folder}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:18:39.137062Z","iopub.execute_input":"2024-12-22T19:18:39.137269Z","iopub.status.idle":"2024-12-22T19:18:49.876289Z","shell.execute_reply.started":"2024-12-22T19:18:39.137252Z","shell.execute_reply":"2024-12-22T19:18:49.875499Z"}},"outputs":[{"name":"stdout","text":"collie sınıfından 650 görsel kopyalandı.\ndolphin sınıfından 650 görsel kopyalandı.\nelephant sınıfından 650 görsel kopyalandı.\nfox sınıfından 650 görsel kopyalandı.\nmoose sınıfından 650 görsel kopyalandı.\nrabbit sınıfından 650 görsel kopyalandı.\nsheep sınıfından 650 görsel kopyalandı.\nsquirrel sınıfından 650 görsel kopyalandı.\ngiant+panda sınıfından 650 görsel kopyalandı.\npolar+bear sınıfından 650 görsel kopyalandı.\n","output_type":"stream"}],"execution_count":389},{"cell_type":"markdown","source":"# Veriyi Yükleme ve Görselleri İşleme ;\n\n* **load_dataset : Belirli bir dizinde bulunan görselleri okur, ön işler ve etiketler ile birlikte bir veri kümesi oluşturur.**\n* **image_dir : Görsellerimizin bulunduğu ana dizindir.**\n* **categories : Modelin öğreneceği sınıf adlarını belirtir.**\n* **label_map : Her sınıfa bir id tanımlar.**\n* **category_path : Her sınıfa ait alt klasörünün oluşturuluyor ve bunlar bu değişkenimizde tutuluyor ve bu sayede gerekli sınıfın olup olmadığını kontrol edebiliyoruz.**\n* **image_files : Görselleri almamıza yarar burada ve random fonksiyonunu kullanarak karıştırmamıza yarar.**\n* **image_name : image_files'dan ilk 650 görüntüyü alıp bundan sonraki adımları bu değişken üzerinde gerçekleşir.**\n* **image_path : Görsellerin dosya yolunu oluşturur.**\n* **image : Bu değişkene Opencv ile okunmuş veriler aktarılır.**\n* **images : İşlenmiş görseller yani boyutu değiştirildikten sonra bu değişkenimize atanır.**\n* **labels : İşlenmiş görsellerin etiketleri bu değişkenimizin içinde tutulur.**\n\n**Bu alanda yaptığımız işlem tam olarak, belirtilen bir dizinden görselleri yükler, her bir görseli uygun boyuta getirir, etiketler ile eşleştirir ve bunları bir NumPy dizisine dönüştürerek eğitim için hazır hale getirir. Ayrıca, her kategoriye ait görsellerin karıştırılması ve sadece ilk 650 görselin alınması gibi işlemlerle, modelin genel doğruluğunu artırmaya yönelik adımlar atılır.**","metadata":{}},{"cell_type":"code","source":"def load_dataset(image_dir):\n    images = []\n    labels = []\n    \n    categories = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \n                  \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \n                  \"giant+panda\", \"polar+bear\"]\n    label_map = {category: idx for idx, category in enumerate(categories)}\n\n    for category in categories:\n        category_path = os.path.join(image_dir, category)\n        if not os.path.exists(category_path):\n            print(f\"Klasör eksik: {category}\")\n            continue\n\n        image_files = os.listdir(category_path)\n        random.shuffle(image_files)\n\n        for image_name in image_files[:650]:\n            image_path = os.path.join(category_path, image_name)\n            image = cv2.imread(image_path)\n            if image is not None:\n                image = cv2.resize(image, (64, 64))\n                images.append(image)\n                labels.append(label_map[category])\n    images = np.array(images)\n    labels = np.array(labels)\n    \n    return images, labels\n\nimage_dir = \"/kaggle/working/selected_animals\"\nimages, labels = load_dataset(image_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:18:49.884177Z","iopub.execute_input":"2024-12-22T19:18:49.884408Z","iopub.status.idle":"2024-12-22T19:19:37.527864Z","shell.execute_reply.started":"2024-12-22T19:18:49.884367Z","shell.execute_reply":"2024-12-22T19:19:37.526902Z"}},"outputs":[],"execution_count":391},{"cell_type":"markdown","source":"# Eğitim ve Test Verilerini Ayırma ve Veri Dönüşümleri ;\n\n# Eğitim ve Test Verilerini Ayırma ;\n\n* **train_test_split(): Bu fonksiyon, verileri rastgele şekilde eğitim ve test setlerine böler.**\n* **images: Görsellerin bulunduğu NumPy dizisi.**\n* **labels: Görsellere ait etiketlerin bulunduğu NumPy dizisi.**\n* **test_size=0.2: Bu parametre, verilerin %20'inin test seti olarak ayrılmasını belirtir. Yani, verilerin geri kalan %80'i eğitim seti olarak kullanılacaktır.**\n* **random_state=42: Bu parametre, rastgelelikğin kontrol edilmesini sağlar. Aynı random_state değeriyle çalışıldığında, her seferinde aynı sonuçları alırsınız. Bu, modelin tekrar edilebilirliğini sağlar.**\n\n# Veri Dönüşümleri(Arttırma) ;\n\n* **transforms.Compose : Birden fazla işlemi ard arda uygulamak için kullanılır.**\n* **ToPILImage : NumPy dizisi veya Tensor'dan bir PIL görüntüsüne dönüştürür.**\n* **RandomHorizontalFlip : Görsellerin rastgele şekilde yatayda çevrilmesini sağlar.**\n* **RandomRotation : Görsellerin rastgele olarak 10 dereceye kadar döndürülmesini sağlar.**\n* **ToTensor : Görseli bir PyTorch tensörüne dönüştürür.**\n* **Normalize : Bu dönüşüm, görsellerin normalizasyonunu yapar.**\n\n\n**Buradaki yazdığımız kod parçası, model eğitimi için verilerin eğitim ve test setlerine ayrılmasını sağlar. Aynı zamanda, eğitim sırasında veriye uygulanacak dönüşümleri de tanımlar. Veri dönüşümleri, modelin daha genelleştirilmiş bir şekilde öğrenmesini ve aşırı uyum sağlamamasını sağlamak için kullanılır.**","metadata":{}},{"cell_type":"code","source":"train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.529173Z","iopub.execute_input":"2024-12-22T19:19:37.529440Z","iopub.status.idle":"2024-12-22T19:19:37.558019Z","shell.execute_reply.started":"2024-12-22T19:19:37.529414Z","shell.execute_reply":"2024-12-22T19:19:37.557279Z"}},"outputs":[],"execution_count":392},{"cell_type":"markdown","source":"# CustomDataset Sınıfı: Veri Kümesi Özelleştirme ;\n\n* **CustomDataset : Bu sınıf, görseller ve etiketlerle özelleştirilmiş bir veri kümesi oluşturur.**\n* **Dataset: PyTorch’un veri kümesi sınıfıdır ve görsel, metin, vb. verilerin nasıl yüklenip işlendiğini tanımlar.**\n* **init : Bu metod, images, labels ve isteğe bağlı olarak transform parametrelerini sınıfın örneği için saklar.**\n* **len : self.images dizisinin uzunluğunu döndürür, yani toplamda kaç görsel olduğunu belirtir.**\n* **getitem : Bu metod, index numarası ile veri kümesinden bir görsel ve etiket alır. Metod, işlenmiş görseli ve etiketini döndürür. Bu, modelin eğitiminde kullanılacak veriyi temsil eder.**","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.558818Z","iopub.execute_input":"2024-12-22T19:19:37.559117Z","iopub.status.idle":"2024-12-22T19:19:37.563691Z","shell.execute_reply.started":"2024-12-22T19:19:37.559089Z","shell.execute_reply":"2024-12-22T19:19:37.562936Z"}},"outputs":[],"execution_count":393},{"cell_type":"markdown","source":"# Eğitim ve Test Veri Setlerinin Oluşturulması ;\n* **train_images, train_labels : Eğitim için kullanılan görseller ve etiketlerdir. Bu veri, eğitim sırasında modelin öğrenmesi için kullanılacaktır.**\n* **test_images, test_labels : Test verisi, modelin eğitildikten sonra doğruluğunu değerlendirebilmek için kullanılır.**\n* **transform : Görsellere uygulanan dönüşümleri içeren bir parametredir**\n\n**train_images ve train_labels ile eğitim veri seti (train_dataset), test_images ve test_labels ile de test veri seti (test_dataset) oluşturulur. Bu veri setleri, daha sonra her bir görüntüyü ve etiketini yükleyebilmek için DataLoader ile kullanılacak.**\n\n# Veri Yükleyicilerinin (DataLoader) Oluşturulması ;\n\n* **train_dataset : Eğitim veri kümesi, önceden CustomDataset sınıfıyla oluşturulmuş ve dönüşümlere tabi tutulmuş eğitim verilerini içerir.**\n* **batch_size : Batch size (mini-batch boyutu), her seferinde modelin eğitim için alacağı örnek sayısını belirtir.**\n* **shuffle : Bu parametre, veri setinin her epoch (eğitim turu) başında karıştırılmasını sağlar.**\n\n**Eğitim verisi için train_loader, test verisi için ise test_loader nesneleri oluşturulur.**","metadata":{}},{"cell_type":"code","source":"train_dataset = CustomDataset(train_images, train_labels, transform=transform)\ntest_dataset = CustomDataset(test_images, test_labels, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.564360Z","iopub.execute_input":"2024-12-22T19:19:37.564563Z","iopub.status.idle":"2024-12-22T19:19:37.568348Z","shell.execute_reply.started":"2024-12-22T19:19:37.564545Z","shell.execute_reply":"2024-12-22T19:19:37.567652Z"}},"outputs":[],"execution_count":394},{"cell_type":"markdown","source":"# CNN Modeli\n\n# Kullandığım Değişkenler ;\n* **in_channels : Giriş kanal sayısıdır. Renkli görsellerde bu değer 3’tür (RGB).**\n* **out_channels : Çıkış kanal sayısıdır ve bu, her konvolüsyonel katmanda öğrenilecek özellik haritasının (feature map) sayısını belirler.**\n* **kernel_size : Konvolüsyonel çekirdek boyutudur.**\n* **stride : Konvolüsyonun hareket adımıdır. Yani, her adımda pencereler ne kadar kayacak.**\n* **padding : Görselin kenarlarına eklenen boşluktur, böylece konvolüsyonel işlem sırasında boyut kaybı önlenebilir.**\n* **MaxPool2d : Max pooling, görselin boyutunu küçültmek için kullanılan bir işlemdir.**\n* **fc_input_size : Bu, son konvolüsyonel katmandan sonra özelliklerin düzleştirilen boyutudur.**\n* **Dropout : Dropout, aşırı uyum (overfitting) önlemek için kullanılan bir tekniktir.**\n* **forward : Bu metod, modelin ileri besleme (forward pass) fonksiyonudur. Girdi verisi, modelin katmanlarından geçer.**\n* **relu : Bu, giriş değerini pozitif olduğu sürece olduğu gibi bırakan, negatif olduğu durumlarda ise sıfıra indirgeyen bir fonksiyondur.**\n* **pool : Daha küçük boyutlara indirgemek amacıyla kullanılan bir işlem türüdür.**\n* **num_classes : Modelin kaç sınıf olduğunu belirtiyor.**\n* **cnn_model = CNNModel(num_classes) : Bu satır, CNN modelini oluşturur ve 10 sınıf için yapılandırılmıştır.**\n* **criterion : Modelin kayıp fonksiyonu belirlenir.**\n* **optimizer_cnn : Modelin parametrelerini optimize etmek için kullanılır ve en uygun optimizer seçilir.**\n\n\n**Bu kod parçası, Convolutional Neural Network (CNN) modelinin yapılandırılmasını ve eğitim için gerekli parametrelerin ayarlanmasını içermektedir. Model, konvolüsyonel katmanlar, max pooling, tam bağlantılı katmanlar ve dropout işlemlerini içerir. Ayrıca, eğitim sırasında kullanılan kayıp fonksiyonu Focal Loss ve optimizasyon için Adam optimizer'ı seçilmiştir.**","metadata":{}},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self, num_classes):\n        super(CNNModel, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        \n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        \n        self.fc_input_size = (64 // 8) * (64 // 8) * 128\n        self.fc1 = nn.Linear(self.fc_input_size, 512)\n        self.fc2 = nn.Linear(512, num_classes)\n        \n        self.dropout = nn.Dropout(0.3)\n        \n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = self.pool(x)\n        x = torch.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.relu(self.conv3(x))\n        x = self.pool(x)\n        \n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\nnum_classes = 10 \ncnn_model = CNNModel(num_classes)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.0005)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.569024Z","iopub.execute_input":"2024-12-22T19:19:37.569213Z","iopub.status.idle":"2024-12-22T19:19:37.602109Z","shell.execute_reply.started":"2024-12-22T19:19:37.569190Z","shell.execute_reply":"2024-12-22T19:19:37.601561Z"}},"outputs":[],"execution_count":395},{"cell_type":"markdown","source":"# Modelin Eğitim Süreci ; \n\n* **model : Eğitim sırasında kullanılacak olan modeldir.**\n* **loader : Eğitim verisini sağlayan DataLoader nesnesidir.**\n* **criterion : Kayıp fonksiyonudur (loss function). Modelin tahminleri ile gerçek etiketler arasındaki farkı hesaplar.**\n* **optimizer: Optimizasyon algoritmasıdır.**\n* **epochs : Bu, eğitim için kullanılacak epoch sayısıdır.**\n* **running_loss : Her epoch başında, o epoch için toplam kaybı tutan bir değişkendir.**\n* **optimizer.zero_grad : Bu komut, her iterasyondan önce optimizer'ın gradyanları sıfırlamasını sağlar.**\n* **outputs : Bu, modelin ileri geçiş (forward pass) işlemidir.**\n* **loss : Bu, kayıp fonksiyonunu çağırıyoruz.**\n* **loss.backward : Bu, kaybın geri yayılımını başlatır. Yani, modelin her parametresinin, kaybı minimize etmek için ne kadar değiştirilmesi gerektiğini hesaplar.**\n* **optimizer.step : Bu komut, modelin parametrelerini günceller.**\n\n**Bu kodumuzda, CNN modelini eğitmek için kullanılan bir eğitim fonksiyonu (train_model) tanımlar. Eğitim sürecini yürütürken modelin parametrelerini optimize eder, kayıp fonksiyonunu minimize etmeye çalışır ve her bir epoch (dönem) sonrasında kayıp değerini yazdırır.**","metadata":{}},{"cell_type":"code","source":"def train_model(model, loader, criterion, optimizer, epochs=30):\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in loader:\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n\n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(loader)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.603809Z","iopub.execute_input":"2024-12-22T19:19:37.604025Z","iopub.status.idle":"2024-12-22T19:19:37.608084Z","shell.execute_reply.started":"2024-12-22T19:19:37.604006Z","shell.execute_reply":"2024-12-22T19:19:37.607416Z"}},"outputs":[],"execution_count":396},{"cell_type":"markdown","source":"# Model'in Değerlendirilmesi ;\n\n* **model.eval(): Modelin değerlendirme moduna geçmesini sağlar**\n* **all_labels ve all_preds : Test verisi üzerinde doğru etiketler (labels) ve modelin tahmin ettiği etiketler (predictions) Bu listeler, tüm test verisi için toplu sonuçları saklamak amacıyla kullanılacak.**\n* **with torch.no_grad : Bu blok, değerlendirme aşamasında gradyan hesaplanmasını devre dışı bırakır.**\n* **_, preds = torch.max(outputs, 1) : torch.max fonksiyonu, her örnek için en yüksek olasılığı veren sınıfı bulur.**\n* **preds: Modelin her bir görsel için tahmin ettiği sınıflardır.**\n* **classification_report : Scikit-learn'ün classification_report fonksiyonu, sınıflandırma sonuçlarını özetleyen bir rapor üretir.**\n* **train_model : train_model fonksiyonunu çağırarak modelin eğitim sürecini başlatır.**\n* **evaluate_model : Bu satır, evaluate_model fonksiyonunu çağırarak eğitim tamamlandıktan sonra test verisi üzerinde modelin başarı performansını değerlendirir**\n\n**Bu fonksiyon, modelin test verisi üzerindeki değerlendirmesini yapar. Test verileri üzerinden yapılan tahminlerin doğruluğu, precision, recall, F1-score gibi metrikler kullanılarak ölçülür. Bu metrikler, modelin ne kadar iyi çalıştığını ve hangi sınıflarda güçlü ya da zayıf olduğunu anlamamıza yardımcı olur.**","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, loader):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for images, labels in loader:\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.numpy())\n            all_preds.extend(preds.numpy())\n    \n    print(classification_report(np.array(all_labels), np.array(all_preds)))\n\ntrain_model(cnn_model, train_loader, criterion, optimizer_cnn, epochs=30)\n\nevaluate_model(cnn_model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:19:37.608859Z","iopub.execute_input":"2024-12-22T19:19:37.609046Z","iopub.status.idle":"2024-12-22T19:33:31.534192Z","shell.execute_reply.started":"2024-12-22T19:19:37.609029Z","shell.execute_reply":"2024-12-22T19:33:31.533085Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/30], Loss: 1.7522353935826775\nEpoch [2/30], Loss: 1.3731751997778021\nEpoch [3/30], Loss: 1.207822297614045\nEpoch [4/30], Loss: 1.0482821113492813\nEpoch [5/30], Loss: 0.9404265741629103\nEpoch [6/30], Loss: 0.8363264086056341\nEpoch [7/30], Loss: 0.7770260234186255\nEpoch [8/30], Loss: 0.7007829695025836\nEpoch [9/30], Loss: 0.6225804656378331\nEpoch [10/30], Loss: 0.5664643367375333\nEpoch [11/30], Loss: 0.4978225829959647\nEpoch [12/30], Loss: 0.4549109420619128\nEpoch [13/30], Loss: 0.4003756979674649\nEpoch [14/30], Loss: 0.35256537772212293\nEpoch [15/30], Loss: 0.3234249966367622\nEpoch [16/30], Loss: 0.2813224673865397\nEpoch [17/30], Loss: 0.2501305250302414\nEpoch [18/30], Loss: 0.23039478918343234\nEpoch [19/30], Loss: 0.19983620228577245\nEpoch [20/30], Loss: 0.1786603434297022\nEpoch [21/30], Loss: 0.1582648059456078\nEpoch [22/30], Loss: 0.1554685043502439\nEpoch [23/30], Loss: 0.15673539962368144\nEpoch [24/30], Loss: 0.14123691285908954\nEpoch [25/30], Loss: 0.1245987615176688\nEpoch [26/30], Loss: 0.11766846899080313\nEpoch [27/30], Loss: 0.10892216782399848\nEpoch [28/30], Loss: 0.10834503209824028\nEpoch [29/30], Loss: 0.1068300048340729\nEpoch [30/30], Loss: 0.09876267000050085\n              precision    recall  f1-score   support\n\n           0       0.68      0.66      0.67       154\n           1       0.87      0.92      0.90       119\n           2       0.85      0.83      0.84       142\n           3       0.64      0.53      0.58       118\n           4       0.71      0.57      0.64       131\n           5       0.72      0.67      0.70       140\n           6       0.60      0.85      0.71       124\n           7       0.59      0.65      0.62       120\n           8       0.86      0.91      0.88       130\n           9       0.89      0.76      0.82       122\n\n    accuracy                           0.74      1300\n   macro avg       0.74      0.74      0.73      1300\nweighted avg       0.74      0.74      0.73      1300\n\n","output_type":"stream"}],"execution_count":397},{"cell_type":"markdown","source":"# Test Doğruluğunu Hesaplama ;\n\n* **all_labels : Gerçek etiketleri tutacak bir liste.**\n* **all_preds : Modelin tahmin ettiği etiketleri tutacak bir liste.**\n* **with torch.no_grad : Bu, gradyan hesaplanmasını devre dışı bırakır, çünkü test aşamasında modelin parametreleri güncellenmez.**\n* **accuracy_score : Bu fonksiyon, Scikit-learn kütüphanesinden gelen bir fonksiyondur ve doğruluğu hesaplar.**\n* **return accuracy : Hesaplanan doğruluk değeri fonksiyonun çıktısı olarak döndürülür.**\n* **cnn_accuracy : Bu komut accuracy_score fonksiyonunu çağırarak CNN modelinin test verisi üzerindeki doğruluğunu hesaplar.**\n* **plt. İşlemleri : Görselleştirmek için kullanılır.**\n\n**Burada ki amacımız, modelin test doğruluğunu hesaplamak ve bunu grafiksel olarak görselleştirmek. İlk olarak, modelin doğruluğu hesaplanır ve daha sonra bu doğruluk yüzde cinsinden yazdırılır. Ardından, model doğruluğu bar grafiği ile görselleştirilir.**","metadata":{}},{"cell_type":"code","source":"def calculate_accuracy(model, loader):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for images, labels in loader:\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_labels.extend(labels.numpy())\n            all_preds.extend(preds.numpy())\n    \n    accuracy = accuracy_score(np.array(all_labels), np.array(all_preds))\n    return accuracy\n\ncnn_accuracy = calculate_accuracy(cnn_model, test_loader)\nprint(f\"CNN Model Doğruluğu: {cnn_accuracy * 100:.2f}%\")\n\nplt.bar(['CNN'], [cnn_accuracy], color=['blue'])\nplt.title('Model Karşılaştırması')\nplt.ylabel('Doğruluk (%)')\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:33:31.535234Z","iopub.execute_input":"2024-12-22T19:33:31.536234Z","iopub.status.idle":"2024-12-22T19:33:34.902983Z","shell.execute_reply.started":"2024-12-22T19:33:31.536205Z","shell.execute_reply":"2024-12-22T19:33:34.901864Z"}},"outputs":[{"name":"stdout","text":"CNN Model Doğruluğu: 72.38%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":398},{"cell_type":"markdown","source":"# Görselleri Manipüle Etmek ;\n\n**Burada yaptığımız işlem, görüntüleri farklı manipülasyonlarla çeşitlendirerek bir veri artırma (data augmentation) stratejisi uygular. Böylece model, daha geniş bir veri çeşitliliğiyle eğitilir ve gerçek dünyadaki karmaşık durumlara (bulanıklık, düşük ışık, dönme, vb.) karşı daha dayanıklı hale gelir.**\n\n**Manipülasyonların Eğitime Dahil Edilmemesi : Eğitim sırasında manipülasyonların uygulanmaması, modelin bu tür verileri tanımakta zorlanmasına yol açar.**\n\n**Model Mimarisi ve Kapasite Eksikliği : Mevcut model, manipüle edilmiş verilerdeki karmaşıklığı yakalamak için yeterince derin olmayabilir daha da gelişmesi gerekiyor olabilir.**\n\n**Eğitim verisi çeşitlendirilerek modelin genelleme yeteneği geliştirilebilir.**","metadata":{}},{"cell_type":"code","source":"def manipulate_image(image):\n    \n    if random.random() > 0.5:\n        image = cv2.flip(image, 1) \n    \n    if random.random() > 0.5:\n        angle = random.randint(-15, 15)\n        rows, cols = image.shape[:2]\n        M = cv2.getRotationMatrix2D((cols // 2, rows // 2), angle, 1)\n        image = cv2.warpAffine(image, M, (cols, rows))\n    \n    if random.random() > 0.5:\n        image = cv2.GaussianBlur(image, (5, 5), 0)\n\n    if random.random() > 0.5:\n        alpha = random.uniform(0.8, 1.2)\n        beta = random.randint(-20, 20)\n        image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n\n    if random.random() > 0.5:\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        hsv[..., 0] = (hsv[..., 0] + random.randint(-10, 10)) % 180\n        image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    \n    return image\n\ndef get_manipulated_images(test_images, output_dir=\"manipulated_images\"):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    manipulated_images = []\n    \n    for i, image in enumerate(test_images):\n        manipulated_image = manipulate_image(image)\n        \n        save_path = os.path.join(output_dir, f\"manipulated_image_{i+1}.png\")\n        \n        cv2.imwrite(save_path, manipulated_image)\n        \n        manipulated_images.append(manipulated_image)\n    \n    print(f\"Manipüle edilmiş resimler '{output_dir}' klasörüne kaydedildi.\")\n    \n    return manipulated_images\n\nmanipulated_test_images = get_manipulated_images(test_images, output_dir=\"manipulated_images\")\n\ndef calculate_accuracy_for_manipulated_images(model, manipulated_images, test_labels):\n    model.eval()\n    all_labels = test_labels\n    all_preds = []\n\n    with torch.no_grad():\n        for image in manipulated_images:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (64, 64))\n            image = transform(image).unsqueeze(0)\n\n            outputs = model(image)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.append(preds.item())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy\n\nmanipulated_accuracy = calculate_accuracy_for_manipulated_images(cnn_model, manipulated_test_images, test_labels)\nprint(f\"Manipüle Edilmiş Test Verileri Doğruluğu: {manipulated_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:33:34.903868Z","iopub.execute_input":"2024-12-22T19:33:34.904224Z","iopub.status.idle":"2024-12-22T19:33:39.725532Z","shell.execute_reply.started":"2024-12-22T19:33:34.904181Z","shell.execute_reply":"2024-12-22T19:33:39.724475Z"}},"outputs":[{"name":"stdout","text":"Manipüle edilmiş resimler 'manipulated_images' klasörüne kaydedildi.\nManipüle Edilmiş Test Verileri Doğruluğu: 25.00%\n","output_type":"stream"}],"execution_count":399},{"cell_type":"markdown","source":"# Renk Sabitliği ;\n\n**Bu kod, görüntülerin renk sabitliğini artırmak için Gray World Algoritması uygulanmasını içerir. Bu algoritma, özellikle farklı aydınlatma koşullarında modelin doğruluğunu nasıl değişim gösterdiğini gözlemlemeyi hedefler**\n\n**Eğitim sırasında Gray World algoritması veya benzer renk sabitliği teknikleri uygularsak burada yaptığımız işlemde daha çok başarı alabiliriz.**\n\n**Retinex Theory veya White Patch Algorithm. Bu algoritmalar daha karmaşık aydınlatma farklılıklarını düzeltebilir. Bu da oranın artmasını sağlayabilir.**\n\n**Görüntü sınıflandırma problemlerinde renk sabitliği, model performansını artırmak için etkili bir tekniktir. Bu kodda kullanılan Gray World algoritması, manipüle edilmiş test görüntülerine uygulanarak modelin doğruluğu ölçülmüştür. Elde edilen sonuçlar, renk sabitliğinin manipüle edilmiş verilere göre beklenen doğruluğun altında kalmıştır belirli denemelerle seviyesi %40'lara çıkmıştır.**","metadata":{}},{"cell_type":"code","source":"def apply_gray_world(image):\n    image = image.astype(np.float32)\n    mean_r = np.mean(image[..., 2])\n    mean_g = np.mean(image[..., 1])\n    mean_b = np.mean(image[..., 0])\n    scale_r = mean_g / mean_r\n    scale_b = mean_g / mean_b\n    image[..., 2] *= scale_r\n    image[..., 0] *= scale_b\n\n    image = np.clip(image, 0, 255).astype(np.uint8)\n    return image\n\ndef get_wb_images(images, output_dir=\"wb_images\"):\n    \n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    wb_images = []\n\n    for i, image in enumerate(images):\n        wb_image = apply_gray_world(image)\n\n        save_path = os.path.join(output_dir, f\"wb_image_{i+1}.png\")\n        cv2.imwrite(save_path, wb_image)\n\n        wb_images.append(wb_image)\n\n    print(f\"Renk sabitliği uygulanmış görüntüler '{output_dir}' klasörüne kaydedildi.\")\n    return wb_images\n\nwb_test_images = get_wb_images(manipulated_test_images, output_dir=\"wb_images\")\n\nwb_accuracy = calculate_accuracy_for_manipulated_images(cnn_model, wb_test_images, test_labels)\nprint(f\"Renk Sabitliği Uygulanmış Test Verileri Doğruluğu: {wb_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T19:33:39.726433Z","iopub.execute_input":"2024-12-22T19:33:39.726723Z","iopub.status.idle":"2024-12-22T19:33:44.283551Z","shell.execute_reply.started":"2024-12-22T19:33:39.726699Z","shell.execute_reply":"2024-12-22T19:33:44.282477Z"}},"outputs":[{"name":"stdout","text":"Renk sabitliği uygulanmış görüntüler 'wb_images' klasörüne kaydedildi.\nRenk Sabitliği Uygulanmış Test Verileri Doğruluğu: 34.85%\n","output_type":"stream"}],"execution_count":400},{"cell_type":"markdown","source":"# Test Setlerinin Başarılarını Karşılaştırma ve Raporlama ;\n\n\n**Orijinal test seti daha yüksek doğruluk oranlarıyla çalışıyor. Şu ana kadar ki En yüksek seviye %78 bandında Ve genel olarak yapılan denemeler şu şekildeydi ;**\n\n    * criterion = nn.CrossEntropyLoss()\n      optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.0005) bunlarla %73 alırken\n    Burada;\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) bunlarla %78 Aldım\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) Burada ise %62 ye geriledim\n\n    Epochs=30 batchsize=64 olarak ve lr=0.0005 ayarında\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.0005) Burada ise %74 ye çıktı\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.SGD(cnn_model.parameters(), lr=0.0005) Burada ise %20ye düştü\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.Rprop(cnn_model.parameters(), lr=0.0005) Burada ise %45ye çıktı\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.AdamW(cnn_model.parameters(), lr=0.0005) Burada ise %74.54ye çıktı\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 256 Burada ise %64 ye geriledim\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 32 Burada ise %70ye çıktım\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 16 Burada ise %73ye\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.0005) batch size 16 Burada ise %70ye\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.001) batch size 16 Burada ise %72ye\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.001) batch size 64 Burada ise %72ye\n\n    criterion = FocalLoss(gamma=2, alpha=0.25)\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.001) batch size 16 Burada ise %71ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.001) batch size 64 Burada ise %69ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 64 Burada ise %73ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 32 Burada ise %72ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.RMSprop(cnn_model.parameters(), lr=0.0005) batch size 128 Burada ise %70ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.0005) batch size 32 Burada ise %75ye\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.AdamW(cnn_model.parameters(), lr=0.0005) batch size 32 Burada ise %69ye\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer_cnn = optim.AdamW(cnn_model.parameters(), lr=0.0005) batch size 64 Burada ise %74ye\n    \n\n**Manipüle edilmiş verilerle doğruluk önemli ölçüde düştü. Görüntüdeki değişiklikler (yatay çevirme, döndürme, bulanıklaştırma vb.) modelin tanıma yeteneğini zayıflatmış.**\n\n    * Bu oranlar yoğunlukla manipüle tarafın %18-%38 arasında oynama gösteriyor burada ki hatam verileri tutmamakdı ama bir çoğunda bu seviyenin üstüne çıkılamıyor du.\n\n\n**Renk sabitliği (Gray World) uygulandıktan sonra doğruluk daha da düşmüş. Bu durum, renk düzeltmesinin modelin orijinal verilerle uyumunu bozduğunu gösteriyor.**\n\n    * Bu oranlar yoğunlukla manipüle tarafın %22-%48 arasında oynama gösteriyor burada ki hatam verileri tutmamakdı ama bir çoğunda bu seviyenin üstüne çıkılamıyor du.\n\n# Düşüş Yaşamada Nedenleri ;\n**Veri manipülasyonunun etkisi: Manipülasyonlar modelin başarısını düşürdü. Modelin genel performansını iyileştirmek için veri augmentasyonu yerine, daha doğru ve anlamlı augmentasyon yöntemlerine yönelmek faydalı olabilir**\n\n**Gray World algoritması: Renk sabitleme gibi işlemler, modelin renk bilgilerini kaybetmesine yol açabilir.**\n\n# Çözüm Önerisi ;\n\n* **Modeli Daha çok çeşitlendirebilirdim renk alanında olsun manipüle kısmında olsun doğruluğu artması için.**\n* **Öğrenme Hızı ve Eğitim süresi daha farklı olabilirdi çok deneme yaptım ama farklı bir eğitim süreci de daha verimli olmasını sağlayabilir.**\n* **Katman sayılarını artırabiliriz belki daha iyi bir sonuç elde edbilirdik.**","metadata":{}}]}